<!doctype html>
<!-- This site was created with Hugo Blox. https://hugoblox.com -->
<!-- Last Published: August 19, 2024 --><html lang="en-us" dir="ltr"
      data-wc-theme-default="system">
  
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="generator" content="Hugo Blox Builder 0.2.0" />

  
  












  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Âë®ÊÆøÊùæ" />

  
  
  
    
  
  <meta name="description" content="The burdensome parameters training of the video models and the inherent multi-frame nature of video jointly pose a significant computational challenge for video action recognition. Recently, parameter-efficient fine-tuning (PEFT) methods have emerged, freezing the visual backbone and only training the lightweight adapters, they address the former issue and effectively adapting image models for video action domains. However, processing multiple frames continues to impede training, with the workload increasing linearly or even quadratically. To tackle the both two issues concurrently, we propose a novel image-to-video adaption paradigm named Select-First-Feed-Then (SFFT) in this work for efficient video action recognition. Specifically, SFFT is composed of two main components, i.e., a novel Video-FrameSelector (VFS) which chooses informative frames based on semantic correlation between video feature and frame representations, and a novel Pos-Adapter for adapting pretrained visual CLIP for video action recognition using only the selected frames. Equipped with VFS and Pos-Adapter, the turning processing of visual CLIP enjoys efficiency from not only the decrement of the parameters need to be tuned, but more directly the reduction of frames fed into CLIP. Technically, VFS and Pos-Adapter both follow the idea of PosMLP-Video that utilizes light-weight relative position encodings to build pairwise spatio-temporal relations and finally build a significant trade-off between effectiveness and efficiency. Experimental results on popular video benchmarks such as Kinetics-400 and Something-Something V2 demonstrate that SFFT achieves SOTA video recognition performance while utilizing significantly fewer parameters and computational resources compared to full fine-tuning CLIP methods or advanced CLIP adaptation methods." />

  
  <link rel="alternate" hreflang="en-us" href="https://example.com/publication/preprint/" />

  
  
  
  
    
    <link rel="stylesheet" href="/css/themes/emerald.min.css" />
  

  
  
    
    <link href="/dist/wc.min.css" rel="stylesheet" />
  

  
  
  

  

  <script>
     
    window.hbb = {
       defaultTheme: document.documentElement.dataset.wcThemeDefault,
       setDarkTheme: () => {
        document.documentElement.classList.add("dark");
        document.documentElement.style.colorScheme = "dark";
      },
       setLightTheme: () => {
        document.documentElement.classList.remove("dark");
        document.documentElement.style.colorScheme = "light";
      }
    }

    console.debug(`Default Hugo Blox Builder theme is ${window.hbb.defaultTheme}`);

    if ("wc-color-theme" in localStorage) {
      localStorage.getItem("wc-color-theme") === "dark" ? window.hbb.setDarkTheme() : window.hbb.setLightTheme();
    } else {
      window.hbb.defaultTheme === "dark" ? window.hbb.setDarkTheme() : window.hbb.setLightTheme();
      if (window.hbb.defaultTheme === "system") {
        window.matchMedia("(prefers-color-scheme: dark)").matches ? window.hbb.setDarkTheme() : window.hbb.setLightTheme();
      }
    }
  </script>

  <script>
    
    document.addEventListener('DOMContentLoaded', function () {
      
      let checkboxes = document.querySelectorAll('li input[type=\'checkbox\'][disabled]');
      checkboxes.forEach(e => {
        e.parentElement.parentElement.classList.add('task-list');
      });

      
      const liNodes = document.querySelectorAll('.task-list li');
      liNodes.forEach(nodes => {
        let textNodes = Array.from(nodes.childNodes).filter(node => node.nodeType === 3 && node.textContent.trim().length > 1);
        if (textNodes.length > 0) {
          const span = document.createElement('label');
          textNodes[0].after(span);  
          span.appendChild(nodes.querySelector('input[type=\'checkbox\']'));
          span.appendChild(textNodes[0]);
        }
      });
    });
  </script>

  
  
  




































  
  

  
  <link rel="icon" type="image/png" href="/media/icon_hu3247630877640252165.png" />
  <link rel="apple-touch-icon" type="image/png" href="/media/icon_hu4166356570829923896.png" />

  <link rel="canonical" href="https://example.com/publication/preprint/" />

  
  
  
  
  
  
  
  
    
  
  

  
  
    
    
  
  <meta property="twitter:card" content="summary_large_image" />
  
    <meta property="twitter:site" content="@GetResearchDev" />
    <meta property="twitter:creator" content="@GetResearchDev" />
  
  <meta property="og:site_name" content="Hugo Academic CV Theme" />
  <meta property="og:url" content="https://example.com/publication/preprint/" />
  <meta property="og:title" content="Adapting CLIP with Select-First-Feed-Then for Efficient Video Action Recognition | Hugo Academic CV Theme" />
  <meta property="og:description" content="The burdensome parameters training of the video models and the inherent multi-frame nature of video jointly pose a significant computational challenge for video action recognition. Recently, parameter-efficient fine-tuning (PEFT) methods have emerged, freezing the visual backbone and only training the lightweight adapters, they address the former issue and effectively adapting image models for video action domains. However, processing multiple frames continues to impede training, with the workload increasing linearly or even quadratically. To tackle the both two issues concurrently, we propose a novel image-to-video adaption paradigm named Select-First-Feed-Then (SFFT) in this work for efficient video action recognition. Specifically, SFFT is composed of two main components, i.e., a novel Video-FrameSelector (VFS) which chooses informative frames based on semantic correlation between video feature and frame representations, and a novel Pos-Adapter for adapting pretrained visual CLIP for video action recognition using only the selected frames. Equipped with VFS and Pos-Adapter, the turning processing of visual CLIP enjoys efficiency from not only the decrement of the parameters need to be tuned, but more directly the reduction of frames fed into CLIP. Technically, VFS and Pos-Adapter both follow the idea of PosMLP-Video that utilizes light-weight relative position encodings to build pairwise spatio-temporal relations and finally build a significant trade-off between effectiveness and efficiency. Experimental results on popular video benchmarks such as Kinetics-400 and Something-Something V2 demonstrate that SFFT achieves SOTA video recognition performance while utilizing significantly fewer parameters and computational resources compared to full fine-tuning CLIP methods or advanced CLIP adaptation methods." /><meta property="og:image" content="https://example.com/publication/preprint/featured.png" />
    <meta property="twitter:image" content="https://example.com/publication/preprint/featured.png" /><meta property="og:locale" content="en-us" />
  
    
      <meta
        property="article:published_time"
        content="2017-01-01T00:00:00&#43;00:00"
      />
    
    <meta property="article:modified_time" content="2019-04-07T00:00:00&#43;00:00">
  

  


    









<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Article",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://example.com/publication/preprint/"
  },
  "headline": "Adapting CLIP with Select-First-Feed-Then for Efficient Video Action Recognition",
  
  "image": [
    "https://example.com/publication/preprint/featured.png"
  ],
  
  "datePublished": "2017-01-01T00:00:00Z",
  "dateModified": "2019-04-07T00:00:00Z",
  
  "author": {
    "@type": "Person",
    "name": "Âë®ÊÆøÊùæ"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Hugo Academic CV Theme",
    "logo": {
      "@type": "ImageObject",
      "url": "https://example.com/media/icon_hu17980401698969639728.png"
    }
  },
  "description": "The burdensome parameters training of the video models and the inherent multi-frame nature of video jointly pose a significant computational challenge for video action recognition. Recently, parameter-efficient fine-tuning (PEFT) methods have emerged, freezing the visual backbone and only training the lightweight adapters, they address the former issue and effectively adapting image models for video action domains. However, processing multiple frames continues to impede training, with the workload increasing linearly or even quadratically. To tackle the both two issues concurrently, we propose a novel image-to-video adaption paradigm named Select-First-Feed-Then (SFFT) in this work for efficient video action recognition. Specifically, SFFT is composed of two main components, i.e., a novel Video-FrameSelector (VFS) which chooses informative frames based on semantic correlation between video feature and frame representations, and a novel Pos-Adapter for adapting pretrained visual CLIP for video action recognition using only the selected frames. Equipped with VFS and Pos-Adapter, the turning processing of visual CLIP enjoys efficiency from not only the decrement of the parameters need to be tuned, but more directly the reduction of frames fed into CLIP. Technically, VFS and Pos-Adapter both follow the idea of PosMLP-Video that utilizes light-weight relative position encodings to build pairwise spatio-temporal relations and finally build a significant trade-off between effectiveness and efficiency. Experimental results on popular video benchmarks such as Kinetics-400 and Something-Something V2 demonstrate that SFFT achieves SOTA video recognition performance while utilizing significantly fewer parameters and computational resources compared to full fine-tuning CLIP methods or advanced CLIP adaptation methods."
}
</script>

  

  


  <title>Adapting CLIP with Select-First-Feed-Then for Efficient Video Action Recognition | Hugo Academic CV Theme</title>

  
  
  
  
  
    
    
  
  
  <style>
    @font-face {
      font-family: 'Inter var';
      font-style: normal;
      font-weight: 100 900;
      font-display: swap;
      src: url(/dist/font/Inter.var.woff2) format(woff2);
    }
  </style>

  

  
  


  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
    
      
      
        
        
          
        
          
        
          
        
          
        
          
        
        
        
      
    
  
  
  
  
  
  
  
  
  
  
  
    
      
      
        
        
          
        
          
        
          
        
          
        
          
        
        
        
      
    
  
    
      
      
        
        
          
        
          
        
          
        
          
        
          
        
        
        
      
    
      
      
        
        
          
        
          
        
          
        
          
        
          
        
        
        
      
    
      
      
        
        
          
        
          
        
          
        
          
        
          
        
        
        
      
    
      
      
        
        
          
        
          
        
          
        
          
        
          
        
        
        
      
    
      
      
        
        
          
        
          
        
          
        
          
        
          
        
        
        
      
    
      
      
        
        
          
        
          
        
          
        
          
        
          
        
        
        
      
    
      
      
    
  
    
      
      
        
        
          
        
          
        
          
        
          
        
          
        
        
        
      
    
      
      
        
        
          
        
          
        
          
        
          
        
          
        
        
        
      
    
      
      
        
        
          
        
          
        
          
        
          
        
          
        
        
        
      
    
      
      
    
  
  
  







<link type="text/css" rel="stylesheet" href="/dist/pagefind/pagefind-ui.be766eb419317a14ec769d216e9779bfe8f3737c80e780f4ba0dafb57a41a482.css" integrity="sha256-vnZutBkxehTsdp0hbpd5v&#43;jzc3yA54D0ug2vtXpBpII=" />


<script src="/dist/pagefind/pagefind-ui.87693d7c6f2b3b347ce359d0ede762c033419f0a32b22ce508c335a81d841f1b.js" integrity="sha256-h2k9fG8rOzR841nQ7ediwDNBnwoysizlCMM1qB2EHxs="></script>


<script>window.hbb.pagefind = {"baseUrl":"/"};</script>

<style>
  html.dark {
    --pagefind-ui-primary: #eeeeee;
    --pagefind-ui-text: #eeeeee;
    --pagefind-ui-background: #152028;
    --pagefind-ui-border: #152028;
    --pagefind-ui-tag: #152028;
  }
</style>

<script>
  window.addEventListener('DOMContentLoaded', (event) => {
    new PagefindUI({
      element: "#search",
      showSubResults: true,
      baseUrl: window.hbb.pagefind.baseUrl,
      bundlePath: window.hbb.pagefind.baseUrl + "pagefind/",
    });
  });
  document.addEventListener('DOMContentLoaded', () => {
    let element = document.getElementById('search');
    let trigger = document.getElementById('search_toggle');

    if (trigger) {
      trigger.addEventListener('click', () => {
        element.classList.toggle('hidden');
        element.querySelector("input").value = ""
        element.querySelector("input").focus()

        if (!element.classList.contains('hidden')) {
          let clear_trigger = document.querySelector('.pagefind-ui__search-clear');

          if (clear_trigger && !clear_trigger.hasAttribute('listenerOnClick')) {
            clear_trigger.setAttribute('listenerOnClick', 'true');

            clear_trigger.addEventListener('click', () => {
              element.classList.toggle('hidden');
            });
          }
        }

      });
    }
  });
</script>















  
  
  
  
  
  
  
  <script
    defer
    src="/js/hugo-blox-en.min.e5fa931947cac2d947732ea37a770aae2b5bd4a50b6048060cd129b46159a06d.js"
    integrity="sha256-5fqTGUfKwtlHcy6jencKritb1KULYEgGDNEptGFZoG0="
  ></script>

  
  








  
    
      
      <script async defer src="https://buttons.github.io/buttons.js"></script>

      
    
  




</head>

  <body class="dark:bg-hb-dark dark:text-white page-wrapper" id="top">
    <div id="page-bg"></div>
    <div class="page-header sticky top-0 z-30">
      
      
      
        
        
        
          <header id="site-header" class="header">
  <nav class="navbar px-3 flex justify-left">
    <div class="order-0 h-100">
      
      <a class="navbar-brand" href="/" title="Hugo Academic CV Theme">
        Diansong Zhou
      </a>
    </div>
    
    <input id="nav-toggle" type="checkbox" class="hidden" />
    <label
      for="nav-toggle"
      class="order-3 cursor-pointer flex items-center lg:hidden text-dark dark:text-white lg:order-1">
      <svg id="show-button" class="h-6 fill-current block" viewBox="0 0 20 20">
        <title>Open Menu</title>
        <path d="M0 3h20v2H0V3z m0 6h20v2H0V9z m0 6h20v2H0V0z"></path>
      </svg>
      <svg id="hide-button" class="h-6 fill-current hidden" viewBox="0 0 20 20">
        <title>Close Menu</title>
        <polygon
          points="11 9 22 9 22 11 11 11 11 22 9 22 9 11 -2 11 -2 9 9 9 9 -2 11 -2"
          transform="rotate(45 10 10)"></polygon>
      </svg>
    </label>
    

    
    
    <ul
      id="nav-menu"
      class="navbar-nav order-3 hidden lg:flex w-full pb-6 lg:order-1 lg:w-auto lg:space-x-2 lg:pb-0 xl:space-x-8 justify-left
      ">
      
      
      
      
      
      
      <li class="nav-item">
        <a
          class="nav-link "
          
          href="/"
        >Bio</a
        >
      </li>
      
      
      
      
      
      
      <li class="nav-item">
        <a
          class="nav-link "
          
          href="/#papers"
        >Papers</a
        >
      </li>
      
      
      
      
      
      
      <li class="nav-item">
        <a
          class="nav-link "
          
          href="/#news"
        >News</a
        >
      </li>
      
      
      
      
      
      
      <li class="nav-item">
        <a
          class="nav-link "
          
          href="/experience/"
        >Experience</a
        >
      </li>
      
      
      
      
      
      
      <li class="nav-item">
        <a
          class="nav-link "
          
          href="/"
        >Life</a
        >
      </li>
      
      
      
    </ul>

    <div class="order-1 ml-auto flex items-center md:order-2 lg:ml-0">

      
      
      
      <button
        aria-label="search"
        class="text-black hover:text-primary  inline-block px-3 text-xl dark:text-white"
        id="search_toggle">
        <svg xmlns="http://www.w3.org/2000/svg" height="16" width="16" viewBox="0 0 512 512" fill="currentColor"><path d="M416 208c0 45.9-14.9 88.3-40 122.7L502.6 457.4c12.5 12.5 12.5 32.8 0 45.3s-32.8 12.5-45.3 0L330.7 376c-34.4 25.2-76.8 40-122.7 40C93.1 416 0 322.9 0 208S93.1 0 208 0S416 93.1 416 208zM208 352a144 144 0 1 0 0-288 144 144 0 1 0 0 288z"/></svg>
      </button>
      

      
      
      <div class="px-3 text-black hover:text-primary-700 dark:text-white dark:hover:text-primary-300
            [&.active]:font-bold [&.active]:text-black/90 dark:[&.active]:text-white">
        <button class="theme-toggle mt-1" accesskey="t" title="appearance">
          <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
               fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
               stroke-linejoin="round" class="dark:hidden">
            <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
          </svg>
          <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
               fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
               stroke-linejoin="round" class=" dark:block [&:not(dark)]:hidden">
            <circle cx="12" cy="12" r="5"></circle>
            <line x1="12" y1="1" x2="12" y2="3"></line>
            <line x1="12" y1="21" x2="12" y2="23"></line>
            <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
            <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
            <line x1="1" y1="12" x2="3" y2="12"></line>
            <line x1="21" y1="12" x2="23" y2="12"></line>
            <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
            <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
          </svg>
        </button>
      </div>
      

      
      

      
      
    </div>
  </nav>
</header>


<div id="search" class="hidden p-3"></div>


        
      
    </div>
    <div class="page-body  my-10">
      




  
    
    
  


<div class="mx-auto flex max-w-screen-xl">
  



<aside class="hb-sidebar-container max-lg:[transform:translate3d(0,-100%,0)] lg:hidden xl:block">
  
  <div class="px-4 pt-4 lg:hidden">
    
    
  </div>
  <div class="hb-scrollbar lg:h-[calc(100vh-var(--navbar-height))]">
    <ul class="flex flex-col gap-1 lg:hidden">
      
      
        <li class=""><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/event/"
    
  >Recent &amp; Upcoming Talks
        <span data-hb-sidebar-toggle>
            <svg fill="none" viewBox="0 0 24 24" stroke="currentColor" class="h-[18px] min-w-[18px] rounded-sm p-0.5 hover:bg-gray-800/5 dark:hover:bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="origin-center transition-transform rtl:-rotate-180"></path></svg>
        </span>
    </a><div class="ltr:pr-0 overflow-hidden">
        <ul class="hb-sidebar-list"><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/event/example/"
    
  >Example Talk
    </a>
              
            </li></ul>
      </div></li>
        <li class=""><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/post/"
    
  >Blog
        <span data-hb-sidebar-toggle>
            <svg fill="none" viewBox="0 0 24 24" stroke="currentColor" class="h-[18px] min-w-[18px] rounded-sm p-0.5 hover:bg-gray-800/5 dark:hover:bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="origin-center transition-transform rtl:-rotate-180"></path></svg>
        </span>
    </a><div class="ltr:pr-0 overflow-hidden">
        <ul class="hb-sidebar-list"><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/post/get-started/"
    
  >üéâ PosMLP-Video is accepted by IJCV.
    </a>
              
            </li></ul>
      </div></li>
        <li class="open"><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/publication/"
    
  >Publications
        <span data-hb-sidebar-toggle>
            <svg fill="none" viewBox="0 0 24 24" stroke="currentColor" class="h-[18px] min-w-[18px] rounded-sm p-0.5 hover:bg-gray-800/5 dark:hover:bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="origin-center transition-transform rtl:-rotate-180"></path></svg>
        </span>
    </a><div class="ltr:pr-0 overflow-hidden">
        <ul class="hb-sidebar-list"><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/publication/conference-paper/"
    
  >PosMLP-Video: Spatial and Temporal Relative Position Encoding for Efficient Video Recognition
    </a>
              
            </li><li class="flex flex-col open"><a
    class="hb-sidebar-custom-link
      sidebar-active-item bg-primary-100 font-semibold text-primary-800 dark:bg-primary-300 dark:text-primary-900"
    href="/publication/preprint/"
    
  >Adapting CLIP with Select-First-Feed-Then for Efficient Video Action Recognition
    </a>
  
              
            </li></ul>
      </div></li>
        <li class=""><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/projects/"
    
  >Projects
    </a></li>
        <li class=""><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/project/"
    
  >Projects
        <span data-hb-sidebar-toggle>
            <svg fill="none" viewBox="0 0 24 24" stroke="currentColor" class="h-[18px] min-w-[18px] rounded-sm p-0.5 hover:bg-gray-800/5 dark:hover:bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="origin-center transition-transform rtl:-rotate-180"></path></svg>
        </span>
    </a><div class="ltr:pr-0 overflow-hidden">
        <ul class="hb-sidebar-list"><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/project/pandas/"
    
  >Pandas
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/project/pytorch/"
    
  >PyTorch
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/project/scikit/"
    
  >scikit-learn
    </a>
              
            </li></ul>
      </div></li>
        <li class=""><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/teaching/"
    
  >Teaching
        <span data-hb-sidebar-toggle>
            <svg fill="none" viewBox="0 0 24 24" stroke="currentColor" class="h-[18px] min-w-[18px] rounded-sm p-0.5 hover:bg-gray-800/5 dark:hover:bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="origin-center transition-transform rtl:-rotate-180"></path></svg>
        </span>
    </a><div class="ltr:pr-0 overflow-hidden">
        <ul class="hb-sidebar-list"><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/teaching/js/"
    
  >Learn JavaScript
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/teaching/python/"
    
  >Learn Python
    </a>
              
            </li></ul>
      </div></li>
        <li class=""><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/_index-copy/"
    
  >
    </a></li>
    </ul>

    <div class="max-xl:hidden h-0 w-64 shrink-0"></div></div>

</aside>
  

<nav class="hb-toc order-last hidden w-64 shrink-0 xl:block print:hidden px-4" aria-label="table of contents">
  











  <div class="hb-scrollbar text-sm [hyphens:auto] sticky top-16 overflow-y-auto pr-4 pt-6 max-h-[calc(100vh-var(--navbar-height)-env(safe-area-inset-bottom))] -mr-4 rtl:-ml-4">

  
  



    












  </div>
  </nav>


  <article class="w-full break-words flex min-h-[calc(100vh-var(--navbar-height))] min-w-0 justify-center pb-8 pr-[calc(env(safe-area-inset-right)-1.5rem)]">
    <main class="w-full min-w-0 max-w-6xl px-6 pt-4 md:px-12">

      

      <h1 class="mt-2 text-4xl font-bold tracking-tight text-slate-900 dark:text-slate-100">Adapting CLIP with Select-First-Feed-Then for Efficient Video Action Recognition</h1>

      <div class="mt-4 mb-16">
      <div class="text-gray-500 dark:text-gray-300 text-sm flex items-center flex-wrap gap-y-2"><span class="mr-1">Apr 7, 2019</span><span class="mx-1">¬∑</span>
        
          
          
          <div class="group inline-flex items-center text-current gap-x-1.5 mx-1">
            
            
            <img src="/author/%E5%91%A8%E6%AE%BF%E6%9D%BE/avatar_hu5640480405136513570.webp" alt="Âë®ÊÆøÊùæ" class="inline-block h-4 w-4 rounded-full border border-current" loading="lazy" />
            
            <div >Âë®ÊÆøÊùæ</div>
          </div>
          
        

        
        <span class="mx-1">¬∑</span>
        <span class="mx-1">
          0 min read
        </span>
        
        </div>

        <div class="mt-3">
          




<div class="">
  
  








  









  
    
  




  





  
  
  
    
  
  
  
  
  
    
  
  <a class="hb-attachment-link hb-attachment-large" href="http://example.org" target="_blank" rel="noopener">
    <svg style="height: 1em" class='inline-block' xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="M13.19 8.688a4.5 4.5 0 0 1 1.242 7.244l-4.5 4.5a4.5 4.5 0 0 1-6.364-6.364l1.757-1.757m13.35-.622l1.757-1.757a4.5 4.5 0 0 0-6.364-6.364l-4.5 4.5a4.5 4.5 0 0 0 1.242 7.244"/></svg>
    Custom Link</a>


</div>


        </div>
      </div>



      
      
      
      
      

      
      
      
      
      
      
      
      
      
      
      <div class="article-header article-container featured-image-wrapper mt-4 mb-16" style="max-width: 720px; max-height: 383px;">
        <div style="position: relative">
          <img src="/publication/preprint/featured_hu3349435048532658638.webp" width="720" height="383" alt="" class="featured-image">
          <span class="article-header-caption">Image credit:</span>
        </div>
      </div>
      

      
      
        <div class="max-w-prose grid grid-cols-1 md:grid-cols-[200px_auto] gap-4 my-6">

        
          <div class="font-bold text-2xl">Abstract</div>
          <div>The burdensome parameters training of the video models and the inherent multi-frame nature of video jointly pose a significant computational challenge for video action recognition. Recently, parameter-efficient fine-tuning (PEFT) methods have emerged, freezing the visual backbone and only training the lightweight adapters, they address the former issue and effectively adapting image models for video action domains. However, processing multiple frames continues to impede training, with the workload increasing linearly or even quadratically. To tackle the both two issues concurrently, we propose a novel image-to-video adaption paradigm named Select-First-Feed-Then (SFFT) in this work for efficient video action recognition. Specifically, SFFT is composed of two main components, i.e., a novel Video-FrameSelector (VFS) which chooses informative frames based on semantic correlation between video feature and frame representations, and a novel Pos-Adapter for adapting pretrained visual CLIP for video action recognition using only the selected frames. Equipped with VFS and Pos-Adapter, the turning processing of visual CLIP enjoys efficiency from not only the decrement of the parameters need to be tuned, but more directly the reduction of frames fed into CLIP. Technically, VFS and Pos-Adapter both follow the idea of PosMLP-Video that utilizes light-weight relative position encodings to build pairwise spatio-temporal relations and finally build a significant trade-off between effectiveness and efficiency. Experimental results on popular video benchmarks such as Kinetics-400 and Something-Something V2 demonstrate that SFFT achieves SOTA video recognition performance while utilizing significantly fewer parameters and computational resources compared to full fine-tuning CLIP methods or advanced CLIP adaptation methods.</div>
        

        
        
          <div class="font-bold text-2xl">Type</div>
          <div>
            <a href="/publication_types/article/">
            Preprint
            </a>
          </div>
        

        

        

        

        

      </div>
      

      <div class="prose prose-slate lg:prose-xl dark:prose-invert">
        
      </div>

      
  <time class="mt-12 mb-8 block text-xs text-gray-500 ltr:text-right rtl:text-left dark:text-gray-400" datetime="2019-04-07T00:00:00.000Z">
    <span>Last updated on</span>
    Apr 7, 2019</time>

      <div class="container mx-auto prose prose-slate lg:prose-xl dark:prose-invert mt-5">
        
        <div class="max-w-prose print:hidden">
  
  

  

<div class="flex justify-center">
  
  <a class="no-underline bg-primary-100 hover:bg-primary-300 text-primary-800 text-xs font-medium mr-2 px-2.5 py-0.5 lg:px-5 lg:py-2 rounded dark:bg-primary-900 dark:hover:bg-primary-700 dark:text-primary-300" href="/tags/video-understanding/">Video Understanding</a>
  
</div>











  
  
    



  
  
  
    
  
  
  

<div class="flex pt-12 pb-4">
  
  
  <img
    class="mr-4 h-24 w-24 rounded-full"
    width="96"
    height="96"
    alt="Âë®ÊÆøÊùæ"
  src="/author/%E5%91%A8%E6%AE%BF%E6%9D%BE/avatar_hu8078565587163403982.jpg"
  loading="lazy"
  />
  
  <div class="place-self-center">
    <div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">
      Authors
    </div>
    <div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">
      <a href="https://example.com/" class="no-underline">
      Âë®ÊÆøÊùæ
      </a>
    </div>

    
    <div class="text-sm font-bold text-neutral-700 dark:text-neutral-300">
    Master Candidate
    </div>
    


    

    <div class="text-2xl sm:text-lg pt-1">

      


    </div>
  </div>
</div>



  




  
  
    
    
    
      
      
    
<div class="pt-1 no-prose w-full">
  <hr class="border-dotted border-neutral-300 dark:border-neutral-600" />
  <div class="flex flex-col md:flex-row flex-nowrap justify-between gap-5 pt-2">
    <div class="">
      
        <a class="group flex no-underline" href="/publication/conference-paper/">
          <span
            class="mt-[-0.3rem] me-2 text-neutral-700 transition-transform group-hover:-translate-x-[2px] group-hover:text-primary-600 dark:text-neutral dark:group-hover:text-primary-400"
          ><span class="ltr:inline rtl:hidden">&larr;</span></span>
          <span class="flex flex-col">
            <span
              class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500"
            >PosMLP-Video: Spatial and Temporal Relative Position Encoding for Efficient Video Recognition</span>
            <span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400">
              
                Jun 27, 2024
              
            </span>
          </span>
        </a>
      
    </div>
    <div class="">
      
    </div>
  </div>
</div>



  


  



</div>

      </div>

    </main>
  </article>
</div>

    </div>
    <div class="page-footer">
      <footer class="container mx-auto flex flex-col justify-items-center text-sm leading-6 mt-24 mb-4 text-slate-700 dark:text-slate-200">

  












  
  
  
  
  














  
  
  

  
  
    
  
  
    
  

  

  
  <p class="powered-by text-center">
    ¬© 2024 Me. This work is licensed under <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" rel="noopener noreferrer" target="_blank">CC BY NC ND 4.0</a>
  </p>
  

  <p class="powered-by footer-license-icons">
    <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" rel="noopener noreferrer" target="_blank" aria-label="Creative Commons">
      <i class="fab fa-creative-commons fa-2x" aria-hidden="true"></i>
      <i class="fab fa-creative-commons-by fa-2x" aria-hidden="true"></i>
      
        <i class="fab fa-creative-commons-nc fa-2x" aria-hidden="true"></i>
      
      
        <i class="fab fa-creative-commons-nd fa-2x" aria-hidden="true"></i>
      
    </a>
  </p>





  <p class="powered-by text-center">
    
    
    
      
      
      
      
      
      
      Published with <a href="https://hugoblox.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Hugo Blox Builder</a> ‚Äî the free, <a href="https://github.com/HugoBlox/hugo-blox-builder" target="_blank" rel="noopener">open source</a> website builder that empowers creators.
    
  </p>

</footer>

    </div>

    
    











  </body>
</html>
